{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VanGogh-se.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9n60Rog25FJ",
        "colab_type": "text"
      },
      "source": [
        "# Van Gogh - se"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJx1P0q34w4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!bash -c 'rm -rf /content/*'\n",
        "!bash -c 'mkdir /content/vangogh'\n",
        "!bash -c 'mkdir /content/vangogh_results'\n",
        "!bash -c 'mkdir /content/photos'\n",
        "!wget -O /content/photos/example.jpeg https://github.com/FabioRick/vangogh-se/releases/download/dataset-v0.1/example.jpeg\n",
        "!wget -O /content/images.zip https://github.com/FabioRick/vangogh-se/releases/download/dataset-v0.1/images.zip\n",
        "!unzip /content/images.zip -d /content/vangogh\n",
        "!bash -c 'rm -rf /content/images.zip'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAVCMllq6HYe",
        "colab_type": "text"
      },
      "source": [
        "Como fazer upload das pinturas desejadas:\n",
        "- Selecine no canto esquerdo os **Arquivos**\n",
        "- Aparecerá uma **árvore de diretórios**\n",
        "- Entre em **/content/vangogh**\n",
        "- Clique com o botão direito na pasta e selecione **Upload**\n",
        "- Espere até que tudo seja concluido para prosseguir\n",
        "\n",
        "Como fazer upload das fotos desejadas:\n",
        "- Selecine no canto esquerdo os **Arquivos**\n",
        "- Aparecerá uma **árvore de diretórios**\n",
        "- Entre em **/content/photos**\n",
        "- Clique com o botão direito na pasta e selecione **Upload**\n",
        "- Espere até que tudo seja concluido para prosseguir\n",
        "\n",
        "Esta etapa só é necessária no caso de reinicialização do notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnCB0WfHyfmo",
        "colab_type": "text"
      },
      "source": [
        "## Importando as bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A26ykk60yiPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import time\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import random\n",
        "from keras.applications import vgg16\n",
        "from keras import backend as K\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVbQtsl9yslf",
        "colab_type": "text"
      },
      "source": [
        "## Populando parâmetros iniciais\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5SYW3t5ywFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir_path = \"/content/photos\"\n",
        "base_image_path = random.choice([ join(base_dir_path, f) for f in listdir(base_dir_path) if isfile(join(base_dir_path, f))])\n",
        "style_reference_dir_path = \"/content/vangogh\"\n",
        "style_reference_image_path = random.choice([ join(style_reference_dir_path, f) for f in listdir(style_reference_dir_path) if isfile(join(style_reference_dir_path, f))])\n",
        "result_prefix = \"/content/vangogh_results\"\n",
        "iterations = 10\n",
        "print(base_image_path)\n",
        "\n",
        "# dimensions of the generated picture.\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = 400\n",
        "img_ncols = int(width * img_nrows / height)\n",
        "\n",
        "# these are the weights of the different loss components\n",
        "total_variation_weight = 1.0\n",
        "style_weight = 1.0\n",
        "content_weight = 0.025\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmZXFCt81b_A",
        "colab_type": "text"
      },
      "source": [
        "## Funções de processamento de imagem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YZZpouS2Egk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# util function to open, resize and format pictures into appropriate tensors\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg16.preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "# util function to convert a tensor into a valid image\n",
        "\n",
        "\n",
        "def deprocess_image(x):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = x.reshape((3, img_nrows, img_ncols))\n",
        "        x = x.transpose((1, 2, 0))\n",
        "    else:\n",
        "        x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEnpiG7f2MIZ",
        "colab_type": "text"
      },
      "source": [
        "## Inicializando modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CUmKGod2OMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get tensor representations of our images\n",
        "base_image = K.variable(preprocess_image(base_image_path))\n",
        "style_reference_image = K.variable(preprocess_image(style_reference_image_path))\n",
        "\n",
        "# this will contain our generated image\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n",
        "else:\n",
        "    combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n",
        "\n",
        "# combine the 3 images into a single Keras tensor\n",
        "input_tensor = K.concatenate([base_image,\n",
        "                              style_reference_image,\n",
        "                              combination_image], axis=0)\n",
        "\n",
        "# build the vgg16 network with our 3 images as input\n",
        "# the model will be loaded with pre-trained ImageNet weights\n",
        "model = vgg16.VGG16(input_tensor=input_tensor,\n",
        "                    weights='imagenet', include_top=False)\n",
        "print('Model loaded.')\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf43PbZirGco",
        "colab_type": "text"
      },
      "source": [
        "## Definindo utilitários para a execução do modelo\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkAHZVS12ffM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute the neural style loss\n",
        "# first we need to define 4 util functions\n",
        "\n",
        "# the gram matrix of an image tensor (feature-wise outer product)\n",
        "\n",
        "\n",
        "def gram_matrix(x):\n",
        "    assert K.ndim(x) == 3\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        features = K.batch_flatten(x)\n",
        "    else:\n",
        "        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram\n",
        "\n",
        "# the \"style loss\" is designed to maintain\n",
        "# the style of the reference image in the generated image.\n",
        "# It is based on the gram matrices (which capture style) of\n",
        "# feature maps from the style reference image\n",
        "# and from the generated image\n",
        "\n",
        "\n",
        "def style_loss(style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))\n",
        "\n",
        "# an auxiliary loss function\n",
        "# designed to maintain the \"content\" of the\n",
        "# base image in the generated image\n",
        "\n",
        "\n",
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))\n",
        "\n",
        "# the 3rd loss function, total variation loss,\n",
        "# designed to keep the generated image locally coherent\n",
        "\n",
        "\n",
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        a = K.square(\n",
        "            x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n",
        "        b = K.square(\n",
        "            x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n",
        "    else:\n",
        "        a = K.square(\n",
        "            x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "        b = K.square(\n",
        "            x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBeuLC622vqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# combine these loss functions into a single scalar\n",
        "loss = K.variable(0.0)\n",
        "layer_features = outputs_dict['block5_conv2']\n",
        "base_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "loss = loss + content_weight * content_loss(base_image_features,\n",
        "                                            combination_features)\n",
        "\n",
        "feature_layers = ['block1_conv1', 'block2_conv1',\n",
        "                  'block3_conv1', 'block4_conv1',\n",
        "                  'block5_conv1']\n",
        "\n",
        "for layer_name in feature_layers:\n",
        "    layer_features = outputs_dict[layer_name]\n",
        "    style_reference_features = layer_features[1, :, :, :]\n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    sl = style_loss(style_reference_features, combination_features)\n",
        "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
        "loss = loss + total_variation_weight * total_variation_loss(combination_image)\n",
        "\n",
        "# get the gradients of the generated image wrt the loss\n",
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if isinstance(grads, (list, tuple)):\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dv9MRd73D1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_loss_and_grads(x):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = x.reshape((1, 3, img_nrows, img_ncols))\n",
        "    else:\n",
        "        x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "    outs = f_outputs([x])\n",
        "    loss_value = outs[0]\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    return loss_value, grad_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwStoVph3V69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Evaluator(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values\n",
        "\n",
        "evaluator = Evaluator()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTZAuENA3Zgf",
        "colab_type": "text"
      },
      "source": [
        "## Rodando a rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4dyaKkO3e3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss\n",
        "x = preprocess_image(base_image_path)\n",
        "fname = result_prefix + '-result.png'\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', i)\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
        "                                     fprime=evaluator.grads, maxfun=20)\n",
        "    print('Current loss value:', min_val)\n",
        "    # save current generated image\n",
        "    img = deprocess_image(x.copy())\n",
        "    end_time = time.time()\n",
        "    print('Iteration %d completed in %ds' % (i, end_time - start_time))\n",
        "    if i == iterations - 1:\n",
        "      save_img(fname, img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGSizHo_4Xyt",
        "colab_type": "text"
      },
      "source": [
        "## The result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw0tKsmH4Y8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(Image(base_image_path, height=400))\n",
        "display(Image(style_reference_image_path, height=200))\n",
        "display(Image(fname, height=400))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}